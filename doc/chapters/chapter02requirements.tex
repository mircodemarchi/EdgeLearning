\section{Task execution time estimation}

The first EdgeLearning integration is the \textbf{estimation of task execution time}. EdgeLearning can execute in parallel multiple tasks, that are represented as numeric integrations of a set that evolves over time. The tasks amount executed during the system evolution before the global integration finishes, is quite a large number. The objective is to find the best schedule of the task with different configurations, in order to obtain the best result in terms of execution time. This implementation can be useful in EdgeLearning, because different tasks could have really different execution time and the predicted execution time of a specified task configuration can be used to improve the threads scheduling. 

Let assume to take in input a vector of bounded integer values, that represents the task parameters configuration for the numeric integration, the output has to be the estimated execution time of input task in microseconds. The task takes another input, in addition to the numeric configuration, that is the initial state of the set. The set is represented as a Taylor expansion with dozen of terms related with the continuous variables of the set space, that is more difficult to represent in the training model of a neural network. The set state has to be taken in consideration during the evolution of system tasks, because the task execution time tends to vary during the temporal evolution of the set, according to its complexity. 

The deep learning model can be initially trained with a sequence of task parameters configurations labelled with their execution time. Then the estimator model has to take in input a task configuration and produce the predicted execution time. Even if the system has to perform multiple task in concurrence, the estimator model is interested in each single task execution. For this reason the most suitable solution for this integration would be a simple Feedforward Neural Network (FNN), without too many layers, in order to avoid an excessive storage of training data.

The prediction model can be improved over time, because when tasks finish their execution, EdgeLearning keeps track of real execution time. Furthermore, the deep learning model has to work well for the last evolution time interval rather than for all evolution, therefore it has to loose memory of oldest executions during online learning and overfitting has to be avoided. To implement this, the estimator has to provide an online learning, in order to give more importance to the latest execution time results obtained.


\section{Parametric dynamic system adaptation}

The second EdgeLearning integration is the \textbf{adaptation of a parametric function that represents the dynamic part of a hybrid system model}. Given a vector of samples, defined on continuous variables, that represent the states of a real system, and an associated hybrid model, we want to get the best accuracy of the hybrid model compared to the real system. Since time evolution is faster than real system evolution, we can use the hybrid model to predict in advance the points that the real system will reach, in order to catch dangerous situations. However, if the hybrid model is not so accurate, the performed prediction will be inaccurate. 

The accuracy of this hybrid model can be improved through some configurable parameters that are given to the functions associated with the model dynamic at each location. The parameters can be defined as point values or, more generally, intervals, and allow to include the samples evolution. In fact, the hybrid model evolution can be represented as a flow channel that is the time evolution of a non-punctual set. The narrower the flow channel, the more accurate the model prediction and the greater the likelihood of including samples of real evolution in the flow channel defined by the sequence of chosen parameters.

The hybrid model evolution is periodically repeated starting from the last sample received by the real system. Therefore, the hybrid model can learn how to improve the sequence of chosen parameter through its errors. The proposed solution is to integrate a deep learning model inside the hybrid model that periodically takes as input the real system state, defined as a sequence of continuous variable samples, and it has to give as output the parameters values for the parametric functions of each dynamic model location that allow the hybrid model to best return a set of points that includes the future real system samples. The output has to be given as an interval, that is a minimum-maximum pair. 

The deep learning model can be trained with a sequence of samples produced by the real system and a related sequence of simulated values produced by the hybrid model of the real system, with a defined parametric function for each hybrid model locations. In addition, the estimator has to be able to improve periodically the accuracy during system execution, for this reason the model has to perform an online learning. Ideally, in a real system that perform over a loop, the learning phase should be executed along all the samples collected in the loop. However, since the loop period is not easily findable, the number of samples on which perform the learning phase is not defined. Finally, this solution needs to define a quality metric of the estimator.

Furthermore, the prediction could be improved with an inference performed along a sequence of samples, because a future state can be found more accurately if the learning model had some of the past sequence of states available. For example a past sequence of states might suggest a direction of the states evolution, if the states evolution is located around a limited area or if it spreads over a large area. For this reason the most suitable solution would be a Recurrent Neural Network (RNN), because it suits really well with temporal sequences. However, the RNN learning model works very well if the real system future state depends on a sequence of previous states, but if the evolution states of a real system depends only on the current state, the usefulness of RNN decreases.

Since there is not a strict necessity to avoid overfitting and the complexity of this use case, compared to the first one, is higher, a good solution could be to implement a Feedforward Neural Network (FNN) with a larger amount of layers, in order to manage better a difficult problem. Therefore, if the RNN does not provide good results then you could opt for the FNN solution.
